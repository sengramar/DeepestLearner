# -*- coding: utf-8 -*-
"""model2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AcZNT2X1-WMBnZgIoYU9tlkJILMMzoif

# Prep
"""

import numpy as np
import random, os, glob
import gzip

import cv2
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

from skimage import feature

from sklearn import metrics
import sklearn.datasets
import seaborn as sns

import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Conv2D, Flatten, MaxPool2D, Dense
from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img
import pathlib
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/MyDrive/deep/assignment_two
!ls
!pwd
#!unzip dataset2.zip

data_dir = '/content/gdrive/MyDrive/deep/assignment_two/Garbage classification/Garbage classification'
classes = os.listdir(data_dir)
print(f"classes: {classes}")

train_datagen = ImageDataGenerator(rescale = 1/255., validation_split=0.15)

test_datagen = ImageDataGenerator(rescale=1/255.0, validation_split=0.15)

train_generator = train_datagen.flow_from_directory(data_dir,
                                                    batch_size = 32,
                                                    shuffle=True,
                                                    target_size = (128, 128),
                                                    subset = "training",
                                                    class_mode='categorical')

val_generator = test_datagen.flow_from_directory(data_dir,
                                                  batch_size = 32,
                                                  shuffle=True,
                                                  target_size = (128, 128),
                                                  subset = 'validation',
                                                  class_mode='categorical')

test_generator = test_datagen.flow_from_directory(data_dir,
                                                    batch_size = 32,
                                                    shuffle=True,
                                                    target_size = (128, 128),
                                                    subset = 'validation',
                                                    class_mode='categorical')

labels = (train_generator.class_indices)
labels = dict((v, k) for k, v in labels.items())
print(labels)

for d_batch, l_batch in train_generator:
  print(f"Data batch shape: {d_batch.shape}")
  print(f"Label batch shape: {l_batch.shape}")
  break

l_batch

model = tf.keras.models.Sequential([
             tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(128, 128, 3)),
             tf.keras.layers.MaxPooling2D(2, 2),
             tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
             tf.keras.layers.MaxPooling2D(2,2),
             tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
             tf.keras.layers.MaxPooling2D(2,2),
             tf.keras.layers.Flatten(),
             tf.keras.layers.Dense(128, activation='relu'),
             tf.keras.layers.Dense(6, activation='softmax')
])

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])
model.summary()

model.fit_generator(train_generator,
                         epochs=20,
                         validation_data=val_generator,
                         steps_per_epoch=50,
                         validation_steps=10)

model.evaluate_generator(test_generator, verbose=2)

model2 = tf.keras.models.Sequential([
             tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(128, 128, 3)),
             tf.keras.layers.MaxPooling2D(2, 2),
             tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
             tf.keras.layers.MaxPooling2D(2,2),
             tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
             tf.keras.layers.MaxPooling2D(2,2),
             tf.keras.layers.Flatten(),
             tf.keras.layers.Dense(128, activation='relu'),
             tf.keras.layers.Dense(6, activation='softmax')
])

model2.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])
model2.summary()

model2.fit_generator(train_generator,
                         epochs=20,
                         validation_data=val_generator,
                         steps_per_epoch=50,
                         validation_steps=10)

model.evaluate_generator(test_generator, verbose=2)
